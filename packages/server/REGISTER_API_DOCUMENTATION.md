# Flowise Dynamic Tool Registration API: `/api/v1/register`

## 1. Overview

The `/api/v1/register` API endpoint allows for the dynamic registration of new tools (specifically "Custom Tools") within Flowise. It takes a natural language query describing a desired API or functionality, utilizes a Large Language Model (LLM) to transform this query into a structured tool specification, and then registers this specification as a new tool in the Flowise system.

This feature is designed to simplify the process of adding new API integrations to Flowise, enabling users or administrators to define tools without manually crafting complex JSON configurations or JavaScript code.

**High-Level Workflow:**

1.  Client sends a `POST` request to `/api/v1/register` with a `user_query`.
2.  The endpoint authenticates the user via their active Flowise session.
3.  The `RegisterServiceController` calls the `LlmService`.
4.  `LlmService` constructs a detailed prompt and queries the configured LLM (e.g., via OpenRouter) with the `user_query`.
5.  The LLM returns a JSON specification for the tool (name, description, input schema, JavaScript function body, color, etc.).
6.  `LlmService` validates the LLM's output, including security checks on the generated JavaScript function.
7.  `RegisterServiceController` uses the validated specification and the user's `activeOrganizationId` and `activeWorkspaceId` to call `ToolService.createTool()`.
8.  The new tool is saved to the database and becomes available as a "Custom Tool" in the Flowise UI for the user's workspace.
9.  A success or error response is returned to the client.

## 2. API Endpoint Details

*   **Endpoint:** `POST /api/v1/register`
*   **Authentication:** Session-based (JWT cookie). Requires an active Flowise user session. Uses the `verifyToken` middleware.

*   **Request Body:** `application/json`
    ```json
    {
        "user_query": "string (required)",
        "target_flowise_tool_name": "string (optional)"
    }
    ```
    *   `user_query`: Natural language description of the API or tool to be created.
    *   `target_flowise_tool_name`: An optional suggested name for the tool. The LLM may use or adapt this suggestion.

*   **Success Response (201 Created):**
    ```json
    {
        "status": "success",
        "message": "API specification generated by LLM and registered successfully.",
        "toolId": "string (ID of the new tool)",
        "toolName": "string (Name of the new tool)",
        "workspaceId": "string (Workspace ID where tool was registered)",
        "orgId": "string (Organization ID associated with the tool)",
        "generatedSpec": {
            "name": "string",
            "description": "string",
            "color": "string (hex color)",
            "iconSrc": "string (optional URL)",
            "schema": "string (JSON string for input schema)",
            "func": "string (JavaScript function body)"
        }
    }
    ```

*   **Error Responses:**
    *   `400 Bad Request`: Missing `user_query`, or LLM generated unsafe/invalid code based on the query.
    *   `401 Unauthorized`: User session is invalid or essential identifiers (`activeOrganizationId`, `activeWorkspaceId`) are missing.
    *   `422 Unprocessable Entity`: LLM output was malformed or missing required fields.
    *   `500 Internal Server Error`: Database error during tool creation or other unexpected server-side issues (e.g., OpenRouter API key not configured).
    *   `502 Bad Gateway`: Failure in communicating with the LLM service or the LLM service returned an error.

## 3. LLM Integration (`LlmService.ts`)

*   **Access Method:** The `LlmService` (`packages/server/src/services/LlmService.ts`) encapsulates all interactions with the LLM.
*   **Configured LLM:**
    *   Accessed via OpenRouter: `https://openrouter.ai/api/v1/chat/completions`.
    *   The specific model is configured using the `LLM_MODEL_NAME` environment variable (e.g., a Llama variant, `anthropic/claude-3-haiku`).
    *   Requires `OPENROUTER_API_KEY` environment variable.
*   **Prompting Strategy:**
    *   The service constructs a detailed prompt instructing the LLM to generate a JSON object representing the tool's specification.
    *   The prompt explicitly asks for fields: `name`, `description`, `color` (hex code), `iconSrc` (optional), `schema` (as a JSON string), and `func` (as a JavaScript async function body string).
    *   **Safety:** The prompt strongly emphasizes generating safe JavaScript code for the `func` field, explicitly forbidding dangerous functions/keywords (`eval`, `fs.`, `child_process`, etc.).
    *   **Credential Handling in `func`:** The prompt guides the LLM to generate `func` code that uses `this.getCredentialData('YOUR_CREDENTIAL_NAME', options)` for API keys or other secrets, rather than hardcoding them. The user must configure these credentials in Flowise.
*   **Output Validation:**
    *   The `LlmService` validates the LLM's JSON output for:
        *   Presence of all required fields.
        *   Correct data types (e.g., `schema` and `func` are strings).
        *   Valid JSON format for the `schema` string.
        *   Valid hex color format for `color`.
        *   Absence of dangerous keywords in the `func` string.

## 4. Flowise Internal Registration Process

*   **Mapping to `Tool` Entity:** The JSON specification generated by the LLM is mapped to the fields of the Flowise `Tool` entity (`packages/server/src/database/entities/Tool.ts`).
*   **Service Call:** The `RegisterServiceController` uses `toolService.createTool(toolObject, orgId)` to save the new tool.
    *   `orgId` is derived from the authenticated user's `activeOrganizationId`.
    *   `toolObject.workspaceId` is set from the user's `activeWorkspaceId`.
*   **Availability:** Once saved, the tool appears in the "Custom Tools" section of the Flowise UI, typically associated with the user's active workspace.

## 5. Key `Tool` Entity Fields Generated/Used

*   `name: string`: Name of the tool (from LLM).
*   `description: string`: Description of the tool (from LLM).
*   `color: string`: Hex color code for UI representation (from LLM).
*   `iconSrc?: string`: Optional URL for an icon (from LLM).
*   `schema: string`: JSON string defining the tool's input parameters (from LLM). Flowise's `CustomTool` runtime uses this to generate input forms and validate inputs (via Zod conversion).
*   `func: string`: JavaScript string (async function body) that executes the tool's logic (from LLM). This code is executed by Flowise's `DynamicStructuredTool` or similar mechanism, with `args` (parsed from `schema`) and `this` (context including `getCredentialData`) available.
*   `workspaceId: string`: Set to the `activeWorkspaceId` of the authenticated user.
*   `orgId: string`: (Passed to `createTool` service method, not a direct field of `ITool` but used for association) Set to `activeOrganizationId` of the authenticated user.

## 6. Security Summary

*   **Authentication:** The endpoint is protected by Flowise's standard session-based authentication (`verifyToken` middleware). Only logged-in users can access it.
*   **`func` Code Validation:**
    *   The LLM is explicitly prompted to generate safe code.
    *   `LlmService` performs a basic check for a list of `DANGEROUS_KEYWORDS` in the generated `func` string and will reject the specification if found.
    *   **Note:** This is a best-effort check. The ultimate safety of the `func` code also relies on the sandboxing capabilities of Flowise's tool execution environment (e.g., `DynamicStructuredTool`).
*   **SSRF (Server-Side Request Forgery):**
    *   The `func` code typically involves making HTTP requests to external APIs. The URLs for these requests are derived from the LLM's output (based on `user_query`).
    *   Currently, there are no explicit allow/deny lists for target URLs. Users should be aware of the potential for the LLM to generate tools that call arbitrary URLs if the `user_query` is crafted maliciously.
*   **Credential Handling:** The system relies on the LLM to generate `func` code that uses Flowise's credential management (e.g., `this.getCredentialData(...)`) rather than hardcoding secrets. Users are responsible for securely configuring these credentials in Flowise.

## 7. Configuration

*   `OPENROUTER_API_KEY` (Environment Variable): Required for `LlmService` to connect to OpenRouter.
*   `LLM_MODEL_NAME` (Environment Variable): Specifies the LLM model to be used via OpenRouter (e.g., `anthropic/claude-3-haiku`, or a Llama model).
*   `FLOWISE_BASE_URL` (Environment Variable, Optional): Used for `HTTP-Referer` header in OpenRouter calls.
*   `FLOWISE_APP_TITLE` (Environment Variable, Optional): Used for `X-Title` header in OpenRouter calls.

## 8. Testing

*   Unit tests have been implemented for:
    *   `LlmService` (`packages/server/tests/services/LlmService.test.ts`): Mocks `node-fetch` to test LLM interaction logic, prompt effects, output parsing, and validation (including security checks).
    *   `RegisterServiceController` (`packages/server/tests/controllers/RegisterServiceController.test.ts`): Mocks `LlmService` and `ToolService` to test request handling, input validation, service integration, and response generation.

## 9. Troubleshooting Guide

*   **"OpenRouter API key not configured"**: Ensure `OPENROUTER_API_KEY` environment variable is set correctly in your Flowise backend environment.
*   **502 Bad Gateway / "Failed to generate API specification from LLM"**:
    *   Check if `OPENROUTER_API_KEY` is valid and has credits.
    *   Verify the `LLM_MODEL_NAME` is correct and available on OpenRouter.
    *   Inspect Flowise server logs for detailed error messages from `LlmService` or OpenRouter.
    *   The LLM might be returning unexpected data; check logs for "LLM returned empty or unexpected content" or "Failed to parse LLM response as JSON".
*   **400 Bad Request / "Generated function code contains potentially dangerous keyword"**: The `user_query` might have led the LLM to generate JavaScript code that was flagged by the security check. Try rephrasing the query or review the LLM's tendencies.
*   **422 Unprocessable Entity / "LLM output is missing required field..."**: The LLM failed to return a complete or correctly structured JSON specification. This might require prompt refinement or checking the LLM's capabilities.
*   **500 Internal Server Error / "Failed to register the new tool in the database"**: Check database connectivity and ensure the `orgId` and `workspaceId` derived from the user session are valid in the context of your database constraints.
*   **General Debugging**: Check Flowise server logs for detailed error stacks and messages from `RegisterServiceController` and `LlmService`. The logs will often contain the exact output from the LLM if parsing or validation failed.
